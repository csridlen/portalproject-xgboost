---
title: "Project"
author: "Christina Ridlen"
date: "5/9/2022"
output: pdf_document
---


```{r libraries, include = FALSE}
library(tidyverse)
library(portalr)
library(lubridate)
library(tidymodels)
```


```{r data_cleaning, include = FALSE}
rodent_data <- read_csv("PortalData/Rodents/Portal_rodent.csv")
species_data <- read_csv("PortalData/Rodents/Portal_rodent_species.csv")

# Select relevant variables
rodent_data <- rodent_data[, c(1, 2, 4, 8, 9, 31)]

# Replace "" with Unknown
rodent_data[rodent_data == ""] <- "Unknown"
rodent_data <- filter(rodent_data, year >= 1989)

# Let's add more descriptions to rodent data from species data
subset <- species_data[, c(1:4)]
subset <- rename(subset, "species" = "speciescode") #rename variable so they match
rodent_data <- full_join(rodent_data, subset, by = "species")

# Create timestamp for rodent data-- we'll need this for merging monthly counts
for(year in rodent_data["year"]){
  for(month in rodent_data["month"]){
    rodent_data["timestamp"] = make_datetime(year, month)
  }
}

# The portalr package allows us to summarize weather data monthly
weather_data_raw <- weather(level = "monthly", fill = TRUE, horizon = 30)

# Data cleaning
weather_data <- filter(weather_data_raw, year >= 1989)

# Select relevant columns
weather_data <- weather_data[, c(c(1:6), 9)]

# Create timestamp
for(year in weather_data["year"]){
  for(month in weather_data["month"]){
    weather_data["timestamp"] = make_datetime(year, month)
  }
}

## Create temperature difference variable
weather_data <- weather_data %>%
  mutate(tempdiff = maxtemp - mintemp)
```

```{r feature_engineering, include = FALSE}
# Create species diversity parameter
  
n_permonth <- rodent_data %>%
  group_by(year, month, species) %>%
  filter(!is.na(year)) %>%
  count() %>%
  group_by(year, month) %>%
  summarize(permonth = sum(n))

percent_change <- as.data.frame(n_permonth) %>%
  mutate(n_permonth = round((permonth/lag(permonth) - 1) * 100, 4))

percent_change[is.na(percent_change)] = 0 # change NA to 0

# Create timestamp for merging
for(year in percent_change["year"]){
  for(month in percent_change["month"]){
    percent_change["timestamp"] = make_datetime(year, month)
  }
}

# Select only time series part with timestamp
percent_change <- subset(percent_change, select = c(n_permonth, timestamp))
```

```{r data_viz, echo = FALSE}
# What are most popular species?
top_5 <- head(rodent_data %>%
  group_by(commonname) %>%
  summarize(n = n()) %>%
  arrange(desc(n)), 5)


plot_data <- rodent_data %>%
  filter(commonname %in% top_5$commonname | scientificname == "Dipodomys spectabilis")

ggplot(plot_data) +
  geom_line(aes(x = timestamp, y = n_permonth, col = species)) + 
  facet_wrap(~commonname, nrow = 6) + 
  ylab("Percent Change per Month") + 
  xlab(" ")
```

```{r time_series, include = FALSE}
#### Time Series Analysis
percent_change$n_permonth = ts(percent_change$n_permonth, deltat = 1/12, start = c(1989, 1, 1))
decm <- decompose(percent_change$n_permonth)


# Remove seasonality
percent_change$n_permonth <- percent_change$n_permonth - decm$seasonal

percent_change$n_permonth <- as.vector(percent_change$n_permonth) # so we can create lags


# Create lagged variable n_permonth
percent_change <- percent_change %>%
  mutate(l1_permonth = lag(n_permonth, n = 1, default = 0),
         l6_permonth = lag(n_permonth, n = 6, default = 0))

### Time series weather data
# Remove seasonality
glimpse(weather_data) # see which variables are time series
weather_ts <- subset(weather_data, select = -c(year, month, timestamp))

for(i in 1:ncol(weather_ts)){
  m <- ts(weather_ts[i], deltat = 1/12, start = c(1989, 1, 1))
  n <- decompose(m)
  j <- m - n$seasonal
  weather_ts[i] = as.vector(j)
}

# Create lagged variables of weather time series
weather_ts <- weather_ts %>%
  mutate(l_tempdiff = lag(tempdiff, n = 1, default = 0),
         l_mintemp = lag(mintemp, n = 1, default = 0),
         l_maxtemp = lag(maxtemp, n = 1, default = 0),
         l_meantemp = lag(meantemp, n = 1, default = 0),
         l_precipitation = lag(precipitation, n = 1, default = 0),
         l_warm_days = lag(warm_days, n = 1, default = 0),
         l_tempdiff = lag(tempdiff, n = 1, default = 0))

weather_lags <- weather_ts[, c(7:12)]
weather_data <- subset(weather_data, select = -c(year, month))
weather_data <- data.frame(weather_data, weather_lags)
```

```{r time_series_plots, echo = FALSE}
plot(decm)
acf(percent_change$n_permonth) # shows MA; 1 and 6 lags significant
```


```{r working_data, include = FALSE}
#### Create working data for modeling
# Join percent_change with weather data by timestamp
working_data <- full_join(percent_change, weather_data, by = "timestamp")
rodent_data <- full_join(rodent_data, working_data, by = "timestamp")
## Remove NA
rodent_data <- na.omit(rodent_data)

rodent_num <- subset(rodent_data, select = -c(timestamp, species, recordID, month, year, species, id, scientificname, taxa, commonname))

```


```{r xgboost, include = FALSE}
### XGBoost

# Train-test split
working_ts <- subset(rodent_num)
working_ts <- na.omit(working_ts)
rodents_split <- initial_split(working_ts, prop = 0.8) # 80% of the data will be training the model
rodents_train <- training(rodents_split)
rodents_test <- testing(rodents_split)

# Create folds for cross-validation
folds <- vfold_cv(rodents_train, v = 5)

# First, create the boosting specification with space for tuning
boost_spec <- boost_tree(
  trees = 500,
  learn_rate = tune(),
  tree_depth = tune(),
  sample_size = tune()) %>%
  set_mode("regression") %>%
  set_engine("xgboost")

# Set up tuning grid for tuning hyper-parameters
tunegrid_boost <- grid_regular(parameters(boost_spec), levels = 2)

tune_results <- tune_grid(boost_spec,
                          n_permonth ~ . ,
                          resamples = folds,
                          grid = tunegrid_boost,
                          metrics = metric_set(rmse))


# Select best parameters
best_boost_params <- select_best(tune_results)
final_boost_spec <- finalize_model(boost_spec, best_boost_params)

boost_model <- final_boost_spec %>% fit(formula = n_permonth ~ .,
                                        data = rodents_train)

## CV in-sample performance
cv_boost <- fit_resamples(final_boost_spec,
                          n_permonth ~ .,
                          resamples = folds,
                          metrics = metric_set(rmse))

in_metrics <- collect_metrics(cv_boost)

# Out-of-sample performance
boost_predictions <- boost_model %>%
  predict(rodents_test) %>%
  bind_cols(rodents_test)


rmse_out_boost <- rmse(boost_predictions,
                       estimate = .pred,
                       truth = n_permonth)
```

```{r xgboost_tables, echo = FALSE}
### Table of best parameters
best_boost_params <- data.frame(subset(best_boost_params, select = -c(.config)))
knitr::kable(best_boost_params, col.names = c("Tree Depth", "Learn Rate", "Sample Size"))


### Table of in-sample performance
in_table <- data.frame(subset(in_metrics, select = -c(.config, .estimator)))
knitr::kable(in_table, col.names = c("Metric", "Mean CV Estimate", "Number of folds", "Standard Error"))
### Table of out-of-sample performance
out_table <- data.frame(subset(rmse_out_boost, select = -c(.estimator)))
knitr::kable(out_table, col.names = c("Metric", "Out-of-Sample Estimate"))

### Variable importance
vip <- vip::vip(boost_model, aesthetics = list(fill = rainbow(10)))
vip

### Partial dependence plots

```



